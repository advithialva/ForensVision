# ForensVision: AI-powered Forensic Video Analysis Tool
[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)  [![FastAPI](https://img.shields.io/badge/FastAPI-0.110+-green.svg)](https://fastapi.tiangolo.com/)  [![Next.js](https://img.shields.io/badge/Next.js-14.0+-black.svg)](https://nextjs.org/)  [![YOLOv8](https://img.shields.io/badge/YOLOv8-Ultralytics-orange.svg)](https://github.com/ultralytics/ultralytics)  [![MoBiLSTM](https://img.shields.io/badge/MoBiLSTM-Violence_Detection-purple.svg)]()


<img width="1340" height="290" alt="Image" src="https://github.com/user-attachments/assets/4ac4ea14-d752-42a4-9ef0-e814fdd7c708" />

ForensVision is an intelligent video analytics platform that aids forensic investigations by automatically detecting violent activities and weapons in uploaded surveillance footage. It features a Python FastAPI backend for efficient model inference and a modern Next.js frontend for seamless video uploads and intuitive visualization of analysis results.

It is designed to assist law enforcement agencies, security professionals, and forensic investigators.


---
## âœ¨ Key Features

- ğŸ¥ Automated analysis of uploaded surveillance videos for violence and weapon detection
- ğŸ”« Custom-trained YOLOv8 model for identifying weapons with high precision
- ğŸ§  Hybrid MoBiLSTM (MobileNet + BiLSTM) architecture for violence recognition
- âš¡ Fast inference powered by a Python FastAPI backend
- ğŸŒ Responsive Next.js frontend for video upload and result visualization

---
## ğŸ’» Tech Stack

| **Category**           | **Technologies Used**                                     |
| ---------------------- | --------------------------------------------------------- |
| **Backend**            | FastAPI Â· Uvicorn Â· Python                                |
| **AI / ML**            | TensorFlow Â· Keras Â· PyTorch Â· YOLOv8                     |
| **Computer Vision**    | OpenCV                                                    |
| **Data Preprocessing** | NumPy Â· Pandas Â· Scikit-learn                             |
| **Frontend**           | Next.js Â· React Â· TypeScript                              |
| **Styling / UI**       | Tailwind CSS Â· Framer Motion                              |
| **Tools**              | Git/GitHub Â· Jupyter Notebook                             |
| **Models**             | MoBiLSTM (Violence Detection) Â· YOLOv8 (Weapon Detection) |

---

## ğŸ“ Project Structure

```
ForensVision
â”œâ”€ backend
â”‚  â”œâ”€ main.py                 # Entry point for the backend server
â”‚  â”œâ”€ config.py               # Configuration
â”‚  â”œâ”€ models/                 # ML model scripts
â”‚  â”œâ”€ utils/                  # Helper functions
â”‚  â”œâ”€ requirements.txt
â”‚  â””â”€ yolov8n.pt
â”œâ”€ frontend
â”‚  â”œâ”€ src/
â”‚  â”‚  â”œâ”€ app/                 # Main app layout and styling files
â”‚  â”‚  â”œâ”€ components/          # Reusable UI components
â”‚  â”‚  â””â”€ services/            # API service layer for backend communication
â”‚  â”œâ”€ package.json
â”‚  â”œâ”€ tailwind.config.ts
â”‚  â””â”€ tsconfig.json
â”œâ”€ models                     # Trained deep learning models
â”‚  â”œâ”€ violence_detection/
â”‚  â””â”€ weapon_detection/
â””â”€ README.md                  # Project documentation
```

---

## ğŸš€ Installation

### ğŸ–¥ï¸ Backend Setup

1. **Clone and navigate to backend**
   ```bash
   git clone https://github.com/advithialva/ForensVision.git
   cd ForensVision/backend
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate

   # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Start the backend server**
   ```bash
   python main.py
   ```
   Server will start at `http://localhost:8000`


### ğŸŒ Frontend Setup

1. **Navigate to frontend directory**
   ```bash
   cd ../frontend
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Start the development server**
   ```bash
   npm run dev
   ```
   Frontend will be available at `http://localhost:3000`

---
## Environment Variables
```bash
# Backend Configuration
CORS_ORIGINS=http://localhost:3000
MAX_FILE_SIZE=500MB
MODEL_DEVICE=auto
```
```bash
# Frontend Configuration
NEXT_PUBLIC_API_URL=http://localhost:8000
```
---
## ğŸ¤– AI Models

### Violence Detection Model
- **Architecture**: MoBiLSTM (Mobile + Bidirectional LSTM)
- **Components**: 
  - LSTM for temporal analysis
  - YOLO for object detection
  - ResNet-50 for visual feature extraction
- **Input**: Video frames with person tracking
- **Output**: Violence probability with component scores

### Weapon Detection Model
- **Architecture**: YOLOv8n (Nano variant for speed)
- **Training**: Custom dataset with multiple weapon types
  
### Model Paths
Models are automatically loaded from the `models/` directory:
- Violence: `models/violence_detection/MoBiLSTM_violence_detection_model.h5`
- Weapons: `models/weapon_detection/weapon_detection.pt`

---
## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---
## ğŸ‘¥ Authors

- **Aaron Fernandes** - [GitHub](https://github.com/aaronfernandes21)
- **Advithi Alva** - [GitHub](https://github.com/advithialva)
- **Pratham R Shetty** - [GitHub](https://github.com/Prathamshettyy)
- **Ryshel Jasmi DSouza** - [GitHub](https://github.com/ryshel-jasmi)
